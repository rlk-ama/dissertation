\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[fleqn]{amsmath}
\usepackage[T1]{fontenc}
\usepackage{parskip}
\usepackage{booktabs}
\usepackage{mathtools}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{natbib}
\usepackage{textcomp}
\usepackage{booktabs}
\usepackage{pgfplots}
\usepackage{pgfplotstable}
\usepackage{array}
\usepackage{bbold}
\usepackage{amssymb}
\usepackage[procnames]{listings}
\usepackage{color}
\usepackage{graphicx}
\graphicspath{ {figures/} }
\usepackage{titlesec}

\makeatletter
\newcommand{\distas}[1]{\mathbin{\overset{#1}{\kern\z@\sim}}}%
\newsavebox{\mybox}\newsavebox{\mysim}
\newcommand{\distras}[1]{%
	\savebox{\mybox}{\hbox{\kern3pt$\scriptstyle#1$\kern3pt}}%
	\savebox{\mysim}{\hbox{$\sim$}}%
	\mathbin{\overset{#1}{\kern\z@\resizebox{\wd\mybox}{\ht\mysim}{$\sim$}}}%
}
\makeatother



\setcounter{secnumdepth}{4}

\titleformat{\paragraph}
{\normalfont\normalsize\bfseries}{\theparagraph}{1em}{}
\titlespacing*{\paragraph}
{0pt}{3.25ex plus 1ex minus .2ex}{1.5ex plus .2ex}


\begin{document}
	\listoffigures
	\listoftables
	\tableofcontents
	
	\clearpage
	\section{Introduction}
	The study of population dynamics, either by ecologists or epidemiologists, often requires the use of elaborate methods. For example, King et al.~\cite{king2008inapparent} and Bhadra et al.~\cite{bhadra2011malaria} studied the spread of epidemics, cholera and malaria, both using iterated filtering for parameter inference of state space models~\cite{ionides2006inference}. The necessity to design such complex inference strategies arises as a consequence of the fact that most of the time population dynamics models are chaotic, or nearly chaotic resulting in multidimensional and multimodal likelihoods. Therefore traditional inference based on numerical methods to find maximum likelihood estimates do not yield satisfactory results. Chaotic behaviour in ecological and epidemiological system is not only of theoretical interest as practical examples abound (see Kausrud et al.~\cite{kausrud2008linking} on lemmings and Anderson et al.~\cite{anderson2008fishing} on fish). \\
	
	Bayesian approaches to inference have become increasingly popular with the recent improvements in computing power. Particle Markov Chain Monte Carlo Methods (PMCMC)~\cite{andrieu2010particle}, which combine a standard Markov Chain Monte Carlo (MCMC) and Sequential Monte Carlo (SMC) algorithms has become a method of choice for inference on such difficult models (see Losa et al.~\cite{losa2003sequential}, Dowd~\cite{dowd2006sequential} and Jones et al.~\cite{jones2010bayesian} for examples in marine ecology). \\
	
	Another recent type of approach, termed likelihood-free or Approximate Bayesian Computation (ABC), and first described by Rubin~\cite{rubin1984bayesianly} has also become popular (see Butler et al.~\cite{butler57latent} for an example in ecology, Tanaka et al.~\cite{tanaka2006using} in epidemiology and Thornton et al.~\cite{thornton2006approximate} in biology). This method consists in simulation from the likelihood when it is impossible to evaluate it, even point wise, as is required in PMCMC. Techniques combining MCMC and ABC (ABC-MCMC) or SMC and ABC (ABC-SMC) to sample from the posterior distribution of the parameters of such models are described respectively in Marjoram et al.~\cite{marjoram2003markov} and Toni et al.~\cite{toni2009approximate}. For a complete review see Marin et al.~\cite{marin2012approximate}. \\
	
	We studied two very famous examples of chaotic population dynamics models from ecology and performed bayesian inference on the parameters of these models using respectively a Particle Marginal Metropolis Hastings (PMMH) sampler as described in Adrieu et al.~\cite{andrieu2010particle}, which is one of the PMCMC algorithms, and a ABC-MCMC sampler. The first model is a noisily observed version of the Ricker map described by Wood~\cite{wood2010statistical} whereas the second one is a solution to the stochastic differential equation suggested by Gurney et al.~\cite{gurney1980nicholson} and Nisbet et al.~\cite{nisbet1982modelling} to describe the last three replicates of the four runs of Nicholsonâ€™s classic experiments on sheep blowfly~\cite{nicholson1954outline}~\cite{nicholson1957self}.
	
	In section 1 of this dissertation a overview of the mathematical background needed to understand the difficulties intrinsic to these two population dynamics models will be given. Section 2 describes the statistical methods used to perform bayesian inference on these two models along with the theoretical reasons, advantages and disadvantages of doing so. Section 3 is dedicated to the actual algorithms that were implemented. Section 4 presents the results attained and contrast them with those obtained by Wood~\cite{wood2010statistical}. Finally a conclusion and a discussion on the merits and limitations of the methods presented is given in the last section.
	
	\section{Two ecological models}
	\subsection{The Ricker Map} 
	\subsubsection{The Deterministic Ricker Map}
	The Ricker map is a difference equation used to describe the population dynamics of a wide range of ecological populations. It was first described in a seminal paper by Ricker~\cite{Ricker1954} to account for fish population sizes in fisheries. \\
	If we denote by $N_t$ the size of a population a time $t$, Ricker established that if:
	\begin{itemize}
		\item the average offspring size per individual per unit time is a constant number $r > 0$
		\item there is a crowding effect which reduces by a factor $e^{-\frac{N_t}{K}}$ the offspring size where $K > 0$
		\item generations do not overlap
	\end{itemize}
	then 
	\begin{equation}
		N_{t+1} = r N_t e^{-\frac{N_t}{K}} = f(N_t)
		\label{eq:ricker}
	\end{equation}
	The fact that generations do no overlap, which is generally a strong assumption in biology, is acceptable in the case of seasonally breeding populations, which are widespread in ecology. \\
	This model has very complex dynamics depending on the values of the parameter $r$. It has become a classic discrete population model, and although not taking into account any of the exterior factors which influence greatly ecological populations (such as destruction of natural ecosystems, pervading pollution, etc ...), it provides an accurate description of many experimental population dynamics (see Krkovsek et al. ~\cite{krkovsek2007declining} or Mueter et al.~\cite{mueter2002opposite} for applications of this model to salmon populations and Gao et al.~\cite{gao2012bayesian} to sixteen representative species from the Global Population Dynamics Database (GPDD)). \\
	
	To understand why estimating the parameters of this model given experimental data is not trivial, we first describe its chaotic behaviour. Equation~\ref{eq:ricker} has two equilibria, $N_{eq, 1} = 0$ and $N_{eq, 2} = K\log r$, which are the solutions of  $N_{eq} = r N_{eq} e^{-\frac{N_{eq}}{K}}$. Linearisation around these two equilibria, give $N_{t+1} - N_{eq, 1} = r(N_{t} - N_{eq, 1})$ and $N_{t+1} - N_{eq, 2} = (1-\log r)(N_{t} - N_{eq, 1})$. Therefore $N_{eq, 1}$ is stable when $0 < r < 1$ and unstable when $r > 1$ and $N_{eq, 2}$ is stable when $1 < r < e^2$ and unstable when $r < 1$ or $r > e^2$. The corresponding bifurcation diagram, with $K$ fixed and equal to 1, is shown in Figure~\ref{fig:stability}. Figure~\ref{fig:stab} shows the convergence towards these two equilibria for respectively $r=0.5$ and $r=3$, with $K=10$ in both cases. It can be noticed that the non zero equilibrium value is close to its theoretical value of $10 \log 3 = 10.9$. \\
	Another interesting characteristic of this map, from an ecological point of view, and the reason why it was so widely adopted, resides in the fact that it accounts for scenarii where populations oscillates before reaching an equilibrium. Figure~\ref{fig:oscill} shows such a scenario.\\
	
	Furthermore, the Ricker Map exhibits another remarkable feature. Indeed, when $r$ exceeds $e^2$ there are no stable equilibrium consisting of a single value. After a transient period, population size starts oscillating among a fixed and finite number of distinct values. The set of these values is called the \emph{orbit}. These values are the fixed points of the equation $f^n(N_t) = N_t$ with $n \in \mathbb{N^*}$ and where $f^n = \underbrace{f\circ f\circ \cdots \circ f}_{n\text{\ times}}$. When $r=e^2$ the orbit consists of 2 values, then of 4 then of 8 and so on until a critical value above which solutions follow an aperiodic pattern. $e^2$ is called a \emph{bifurcation value}, and this geometric progression in the length of the cycles is called a \emph{period doubling cascade}. Figure~\ref{fig:stability} represents the orbit as $r$ grows ($K$ is fixed and equal to 1) and was obtained experimentally. It can be seen that when $r=e^2$ the orbit consists of 2 values and of 8 when $r=2e^2$. Figure~\ref{fig:oscill} shows such an orbit of four values.
	
	As $r$ continues growing, we rapidly reach a situation where population size does not enter any stable orbit any more. This leads to a behaviour characteristic of chaos, where a small change in the value of the parameters or the initial conditions leads to very different solutions. Figure~\ref{fig:chaos} shows the evolution of two populations when either parameter $r$ or initial conditions present a very minor change. It can be noted that populations sizes, in both cases, diverges rapidly from one another.
	
	\subsubsection{The Noisily Observed Ricker Map}
	In order to allow for external and internal stochasticity~\cite{wang2007latent} and to take into account the observational process~\cite{calder2003incorporating} (for example a counting process of salmons in fisheries), extensions to the deterministic case have been suggested. We chose to proceed with the following model, suggested by Wood (2010)~\cite{Wood2010}.
	\begin{align}
	& N_t = r N_t e^{-N_t+Z_t} \hspace{1cm} Z_t \distas{\mathrm{iid}} \mathrm{N}(0, \sigma^2) \label{noisyRickerState}\\
	& Y_t = \mathrm{Poisson}(\phi N_t)
	\label{noisyRickerObservation}
	\end{align}
	Therefore, $N_t \sim \log\mathcal{N} (\log{(rN_{t-1}e^{-N_{t-1}})},\sigma^2)$, i.e $N_t$ is log-normally distributed with parameters depending on $r$, $K$ and $\sigma$. \\
	
	This models belongs to the framework of state space models which have been widely used to describe population dynamics~\cite{lillegaard2008estimation}~\cite{zhang2009spatial}~\cite{zhang2010computational} as it allows for great flexibility, encompassing models ranging from linear gaussian to highly non-linear and non-gaussian. 
	
	The statistical problem at hand is to estimate the joint probability of $(r, K, \sigma, \phi)$ in order to determine which of the regimes described earlier drives the observed population. Due to the chaotic dynamics of the Ricker map, estimating these coefficients with precision is important if one wants to obtain simulations exhibiting the same properties as experimental data. However, such an erratic behaviour leads to a highly multimodal likelihood and traditional approaches do not suit this parameter estimation problem. \\
	Moreover, even if the map were not chaotic, the likelihood is a highly dimensional integral over $N_{0:T}$ (for ease of notation we denote $N_{0:T} \coloneqq \{N_0, N_1, \cdots, N_T\}$). Indeed we have:
	\begin{equation}
		L(y_{1:T}; \phi, r, \sigma) = \int_{0}^{\infty}p(y_{1:T}, n_{0:T} | \phi, r, \sigma)\mathrm{d}n_{0:T}
	\end{equation}
	and $T$ is ranges typically from 30 to several hundreds. Therefore classic numerical integration tools, or Markov Chain Monte Carlo algorithms which require calculation, up to a constant, of the likelihood, are not suited for this problem. Therefore a wealth of techniques have been designed solve this problem: iterated filtering~\cite{ionides2006inference}, data cloning~\cite{lele2007data} and adaptative PMCMC~\cite{peters2010ecological}.
	
	\subsection{Nicholson's experiment on Sheep Blowflies}
	
	\clearpage
	\section{Inference Methods}
	\subsection{State Space Model}
	State space models describe sets of processes which can be decomposed into the following form where $\mathrm{X}=\{x_t ; t \in \mathbb{N}\}$ is a discrete time with $x_t \in \Omega_s$ and $\mathrm{Y}=\{y_t ; t \in \mathbb{N^*}\}$ is another discrete time process with $y_t \in \Omega_o$, $\Omega_s$, $\Omega_o$ being samples spaces. The $x_t$'s are unobserved and are called the \emph{hidden states} and the $y_t$ are the \emph{observations}. Moreover, $\theta$ is a vector of parameters on which both the distribution of $\mathrm{X}$ and $\mathrm{Y}$ depend. For the purposes of this dissertation, $\Omega_s, \Omega_o \subseteq \mathbb{R}$ and $\theta \in \mathbb{R}^k$, $k \in \mathbb{N^*}$. This can be summarized as follow: 
	\begin{align}
		& p(x_0, \theta) \\
		& p(x_t | x_{t-1}, \theta) \hspace{1cm} t \ge 1\\
		& p(y_t | x_t, \theta) \hspace{1cm} t \ge 1
	\end{align}
	Note that we denote by $p(x_t)$ both the probability density of $X_t$ and its distribution if it exists, with respect to an underlying measure $\lambda$. This set of equations means that $X_t$ is a Markov process of initial distribution $p(x_0)$ and transition distribution $p(x_t | x_{t-1})$ and that the observations $y_t$ are assumed to be independent conditionally on $\{x_t ; t \in \mathbb{N}\}$, i.e $p(y_1, \cdots, y_t | x_0, \cdots, x_t) =p(x_0)\Pi_{k=1}^t p(y_k | x_k)$ where $p(y_k | x_k)$ is the marginal distribution of $y_k$. We can therefore decompose the full joint density as follows:
	\begin{align}
	\underbrace{p(x_{0:T}, y_{0:T}, \theta)}_{\text{joint}} & = \underbrace{p(x_{0:T}, \theta)}_{\text{prior}}\underbrace{p(y_{1:T}| x_{0:}, \theta)}_{\text{likelihood}} \\
		& = p(\theta)p(x_0| \theta)\prod_{k=1}^{T}p(x_k|x_{k-1}, \theta)\prod_{k=1}^{T}p(y_k|x_k, \theta)
	\end{align}\\
	
	\subsubsection{Inference on State Space Models}
	Bayesian inference on state space models consists in obtaining, conditioned on a particular dataset $y_{1:T}$, the \emph{posterior distribution} $p(x_{0:T}, \theta| y_{1:T})$. This task is divided between \emph{parameter estimation}, i.e obtaining $p(\theta | y_{1:T})$  and \emph{state estimation}, i.e obtaining $p(x_{0:T}|y_{1:T}, \theta)$. \\
	Traditional methods used for bayesian inference, such as Metropolis-Hastings and Gibbs sampling are, in most of the cases, not usable as the posterior distribution and the transition density are not known distributions and even seldom have closed forms (which precludes computation of the Metropolis Hastings acceptance ratio and of the full conditional distributions in Metropolis Hastings within Gibbs). Examples of this situation abound~\cite{beskos2006exact}~\cite{fearnhead2008particle}~\cite{murray2011particle}. Even if these closed forms were available, states are usually strongly correlated and are also often correlated with model parameters. In this case, both Metropolis Hasting and Gibbs samplers are known to perform poorly~\cite{van2011partially}. \\

	
	\paragraph{Parameter estimation}
	In both of the population dynamic models presented earlier, the aim is to perform parameter estimation so as to understand which regime the population at hand is in, and to be able to carry out simulations. \\
	To achieve this the marginal Metropolis Hastings algorithm~\cite{hastings1970monte}, combined with methods to obtain samples from  $p(x_{0:t}| y_{1:t}, \theta)$ and to calculate unbiased estimates of the likelihood, is a method of choice. \\
	This algorithm samples in fact from $p(\theta, x_{0:T} | y_{1:T})$ and is a otherwise a simple Metropolis Hastings (MH) sampler. The proposal, which matches the structure of $p(x_{0:T}, \theta | y_{1:T})$ is of the form: $q((\theta^*, x_{0:T}^*) | (\theta, x_{0:T})) = q(\theta^* | \theta)p(x_{0:T}^* | y_{1:T}, \theta^*)$ and the acceptance ratio of the MH algorithm is: 
	\begin{align*}
	\frac{p(\theta^*, x_{0:T}^* | y_{1:T})q(\theta^ | \theta^*)p(x_{0:T} | y_{1:T}, \theta)}{p(\theta, x_{0:T} | y_{1:T})q(\theta^* | \theta)p(x_{0:T}^* | y_{1:T}, \theta^*)} & = \frac{p(\theta^* | y_{1:T})q(\theta | \theta^*)}{p(\theta | y_{1:T})q(\theta^* | \theta)} \\
	& = \frac{p(y_{1:T} | \theta^*)p(\theta^*)q(\theta | \theta^*)}{p(y_{1:T}|\theta)p(\theta)q(\theta^* | \theta)}
	\end{align*}
	
	It can be noted that the terminology comes from the fact that the ratio seems to be targeting $p(\theta | y_{1:T})$.
	
 	When the relationship between states and the one between states and observations are linear and gaussian, Kalman (1960)~\cite{Kalman1960} designed a method which allows to sequentially calculates the \emph{filtering distribution}, i.e $p(x_{t}| y_{1:t}, \theta)$, which in this particular case has a closed form. From there, it is easy to recover the likelihood marginalised over $x_{0:T}$ and to sample from $p(x_{0:t}| y_{1:t}, \theta)$. In this case the proposal $q(x_{0:t}| y_{1:t}, \theta)$ Although variants of this original filter, which deal with non-linear and non-gaussian state space miodels, have been designed, such as the extended~\cite{McElhoe1966} and unscented~\cite{Julier1997} Kalman filters, they give biased estimates of $p(x_t|y_{1:t}, \theta)$. \\
 	
 	In these non-linear, non-gaussian cases, the \emph{particle filter}~\cite{Gordon1993}, which is of the family of Sequential Monte Carlo (SMC) methods, provides estimates of $p(y_{1:T}, \theta)$ and of $p(x_{0:T}|y_{1:T}, \theta)$ which, when used as the proposal distribution, leaves invariant $p(x_{0:T}, \theta|y_{1:T})$ and ensures that the marginal Metropolis Hastings sampler is ergodic. This version of the algorithm is commonly referred to as the Particle Marginal Metropolis Hastings (PMMH) sampler and is described, along with the proof that it is indeed ergodic under mild assumptions in Andrieu et al.~\cite{andrieu2010particle}.
	
	\subsubsection{Particle Filter}
	We describe a little further the particle filter as it is the method we applied in order to estimate the likelihood and sample from $p(x_{0:T}|y_{1:T}, \theta)$ to carry out parameter inference in the case of the noisily observed Ricker map. \\
	This method is based on sequential importance sampling.
	The idea behind importance sampling is to approximate $p(x_{1:t}|y_{1:t}, \theta)$ with the empirical distribution
	\begin{equation}
	\hat{p}(x_{0:t}|y_{1:t}, \theta) = \sum_{i=1}^{N}\tilde{w}_t^{(i)} \delta_{x_{0:t}^{(i)}}(x_{0:t})
	\end{equation}
	where $\tilde{w}_t^{(i)} = \frac{W(x_{0:t}^{(i)})}{\sum_{j=1}^{N} W(x_{0:t}^{(j)})}$ and $W(x_{0:t}) = \frac{p(x_{1:t},y_{1:t}, \theta)}{q(x_{1:t})}$ where $x_{0:t}^{(i)}$ are iid draws from $q(x_{1:t})$, which is an easy to sample from distribution.
	
	However, this method does not take advantage of dependency structure of the state space model. Indeed, the weights $W(x_{0:t})$ can be expressed sequentially using the fact that the $y_t$ are conditionally independent given $x_{0:t}$ and that the $x_t$ have the Markov property. Moreover a choice of proposal distribution which also has the Markov property (i.e $q(x_{1:t})=q(x_{1:t-1})q(x_t| x_{t-1})$) allows us to write:
	\begin{align}
		W(x_{0:t}) & = \frac{p(x_{0:t},y_{1:t}, \theta)}{q(x_{0:t},y_{1:t}, \theta)} \\
		& = p(y_t|x_t)p(x_t|x_{t-1})
	\end{align}
	
	 If we take any bounded measurable function $\phi$ Geweke (1989)~\cite{Geweke1989} showed, under certain conditions, that $\mathrm{I_N^{IS}}=\mathbb{E_{\hat{p}}}\phi(x_{0:t}) = \sum_{i=1}^{N} \tilde{w}_t^{(i)} \phi(x_{0:t}^{(i)}) \xrightarrow{\mathrm{a.s}} \int_{\Omega^n} \phi({x_{0:t}})p(x_{0:t}|y_{1:t})\mathrm{d}x_{0:t}=\mathbb{E_{{p}}}\phi(x_{0:t})$, and moreover that the bias and the variance are $\mathcal{O}(\frac{1}{N})$.\\
	 
	 However, as shown in ~\cite{kong1994sequential}, the variance of the weights is exponential in the number $n$ of time steps. Moreover, the effective sample size (ESS), as defined in ~\cite{liu2008monte} pp 35-36, which measures the ratio between the variance of $\mathrm{I_N^{IS}}$ and of the same quantity if the samples were independently drawn from the true distribution, vanishes quickly.
	 
	The most simple form of particle filter, also called \emph{bootstrap filter} relies on the 
	\begin{figure}[htb]
		\centering
		\begin{minipage}{0.4\textwidth}
			\centering
			\includegraphics[width=0.97\linewidth]{/home/raphael/dissertation/figures/stability.pdf}
		\end{minipage}
		\begin{minipage}{0.4\textwidth}
			\centering
			\includegraphics[width=0.97\linewidth]{/home/raphael/dissertation/figures/bifucdiagram.pdf}
		\end{minipage}
		\caption{\textbf{(left)}Bifurcation diagram of the Ricker map. \textbf{Dotted} lines correspond to unstable equilibria and \textbf{solid} lines to stable ones. \textbf{(right)} Bifurcation diagram of the Ricker Map.}
		\label{fig:stability}
	\end{figure}

	\begin{figure}[htb]
		\centering
		\begin{minipage}{0.4\textwidth}
			\centering
			\includegraphics[width=0.97\linewidth]{/home/raphael/dissertation/figures/0value_ricker.pdf}
		\end{minipage}
		\begin{minipage}{0.4\textwidth}
			\centering
			\includegraphics[width=0.97\linewidth]{/home/raphael/dissertation/figures/stable_ricker.pdf}
		\end{minipage}
		\caption{Convergence towards the equilibria of the Ricker map}
		\label{fig:stab}
	\end{figure}

	\begin{figure}[htb]
		\centering
		\begin{minipage}{0.4\textwidth}
			\centering
			\includegraphics[width=0.97\linewidth]{/home/raphael/dissertation/figures/oscill_ricker.pdf}
		\end{minipage}
		\begin{minipage}{0.4\textwidth}
			\centering
			\includegraphics[width=0.97\linewidth]{/home/raphael/dissertation/figures/4values_ricker.pdf}
		\end{minipage}
		\caption{\textbf{(left)} The population size oscillates before converging towards equilibrium. \textbf{(right)} The population sizes describes an orbit of length four.}
		\label{fig:oscill}
	\end{figure}
	
	\begin{figure}[htb]
		\centering
		\begin{minipage}{0.4\textwidth}
			\centering
			\includegraphics[width=0.97\linewidth]{/home/raphael/dissertation/figures/rchange.pdf}
		\end{minipage}
		\begin{minipage}{0.4\textwidth}
			\centering
			\includegraphics[width=0.97\linewidth]{/home/raphael/dissertation/figures/initchange.pdf}
		\end{minipage}
		\caption{\textbf{(left)} Evolution of the population size when \textbf{(black)}$r=50$ and \textbf{(red)}$r=50.1$ with initial value $N_0=7$. \textbf{(right)} Evolution of the population size when \textbf{(black)}$N_0=7$ and \textbf{(red)}$N_0=7.1$ with $r=50$.}
		\label{fig:chaos}
	\end{figure}

\clearpage
	\section{Bibliography}
	\bibliographystyle{plain}
	\bibliography{mybib}{}
\end{document}