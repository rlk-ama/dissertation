\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[fleqn]{amsmath}
\usepackage[T1]{fontenc}
\usepackage{parskip}
\usepackage{booktabs}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{natbib}
\usepackage{textcomp}
\usepackage{booktabs}
\usepackage{pgfplots}
\usepackage{pgfplotstable}
\usepackage{array}
\usepackage{bbold}
\usepackage{amssymb}
\usepackage[procnames]{listings}
\usepackage{color}
\usepackage{graphicx}

\addtolength{\oddsidemargin}{-.875in}
\addtolength{\evensidemargin}{-.875in}
\addtolength{\textwidth}{1.75in}

\addtolength{\topmargin}{-.875in}
\addtolength{\textheight}{1.75in}

\makeatletter
\newcommand{\distas}[1]{\mathbin{\overset{#1}{\kern\z@\sim}}}%
\newsavebox{\mybox}\newsavebox{\mysim}
\newcommand{\distras}[1]{%
	\savebox{\mybox}{\hbox{\kern3pt$\scriptstyle#1$\kern3pt}}%
	\savebox{\mysim}{\hbox{$\sim$}}%
	\mathbin{\overset{#1}{\kern\z@\resizebox{\wd\mybox}{\ht\mysim}{$\sim$}}}%
}
\makeatother

\title{Gamma approximation of Log Normal distribution for Ricker Map Inference}
\author{Raphael Lopez Kaufman}
\date{}

\begin{document}
	We want to simulate from $p(r_{1:n}, s_{1:n} | n_{1:n})$ and to calculate $p(n_{1:n})$ where
	\begin{equation*}
		N_t = S_t + R_t
	\end{equation*}
	\begin{equation*}
		R_t \sim \mathrm{Poisson}(PN_{t-\tau}e^{\frac{N_{t-\tau}}{N_0}}e_t)
	\end{equation*}
	\begin{equation*}
	S_t \sim \mathrm{Binomial}(e^{-\delta\epsilon_t}, N_{t-1})
	\end{equation*}
	where $e_t \sim \mathrm{Gamma(\sigma_p^{-2}, \sigma_p^{-2})}$ and $\epsilon_t \sim \mathrm{Gamma(\sigma_d^{-2}, \sigma_d^{-2})}$ Indeed, in Wood's paper $e_t$ and $\epsilon_t$ are described as Gamma distributed with unit mean and respective variances $\sigma_p^2$ and $\sigma_d^2$. Yet if $\mathrm{X} \sim \mathrm{Gamma}(\alpha, \beta)$ then $\mathrm{E}(\mathrm{X}) = \frac{\alpha}{\beta}$ and $\mathrm{Var}(\mathrm{X}) = \frac{\alpha}{\beta^2}$ leading in our case to $\alpha=\beta=\sigma^{-2}$
	
	To this effect we are going to use the following particle filter algorithm:
	\begin{itemize}
		\item sample $S_t^{(i)} \sim q_s(\ \cdot \ ; N_{t-1}^{(i)}, N_t)$
		\item sample $R_t^{(i,j)} \sim q_r(\ \cdot \ ; N_{t-\tau}^{(i)}, N_t)$
		\item set $W_t^{(i)} \propto \hat{p}(N_t |S_t^{(i)})\frac{g_s(S_t^{(i)} | N_{t-1}^{(i)})}{q_s(S_t^{(i)} | N_{t-1}^{(i)}, N_t)}$
		where $\hat{p}(N_t |S_t^{(i)}) = \frac{1}{M}\sum_{j=1}^{M}\delta_{N_t}(S_t^{(i)}+R_t^{(i,j)})\frac{g_r(R_t^{(i,j)} | N_{t-\tau}^{(i)})}{q_r( R_t^{(i,j)}| N_{t-\tau}^{(i)}, N_t)}$
	\end{itemize}
	
	$R_t$ and $S_t$ are compounded distributions.
	First $R_t | N_{t-\tau}$ has a probability density such that:
	\begin{equation*}
	\begin{split}
			g_r(r_t | n_{t-\tau}) & = \int_{0}^{\infty}g_r(r_t, e_t | n_{t-\tau})\ \mathrm{d}e_t \\
			& = \int_{0}^{\infty}g_r(r_t | e_t, n_{t-\tau})p(e_t | n_{t-\tau})\ \mathrm{d}e_t \\
			& = \int_{0}^{\infty}g_r(r_t | e_t, n_{t-\tau})p(e_t)\ \mathrm{d}e_t \\
			& = \int_{0}^{\infty}e^{-\beta(n_{t-\tau})e_t}\frac{(\beta(n_{t-\tau})e_t)^{r_t}}{\Gamma(r_t+1)}\frac{\alpha^\alpha}{\Gamma(\alpha)}e_t^{\alpha-1}e^{-\alpha e_t}\ \mathrm{d}e_t \\
			& = \frac{\beta(n_{t-\tau})^{r_t}}{\Gamma(r_t+1)}\frac{\alpha^\alpha}{\Gamma(\alpha)}\int_{0}^{\infty}e^{-(\beta(n_{t-\tau})+\alpha)e_t}e_t^{r_t+\alpha-1}\ \mathrm{d}e_t \\
			& = \frac{\beta(n_{t-\tau})^r_t}{\Gamma(r_t+1)}\frac{\alpha^\alpha}{\Gamma(\alpha)}\frac{\Gamma(r_t+\alpha)}{(\beta(n_{t-\tau})+\alpha)^{r_t+\alpha}} \\
			& = \binom{r_t + \alpha - 1}{r_t}(\frac{\beta(n_{t-\tau})}{\beta(n_{t-\tau}) + \alpha})^{r_t}(\frac{\alpha}{\beta(n_{t-\tau}) + \alpha})^\alpha
	\end{split}
	\end{equation*}
	where $\beta(n_{t-\tau}) = Pn_{t-\tau}e^{-\frac{n_{t-\tau}}{N_0}}$ and $\alpha = \sigma_p^{-2}$
	In the last equation we recognise a Negative-Binomial distribution with parameter $\frac{\alpha}{\beta(n_{t-\tau}) + \alpha}$ and $\alpha$
	
	As for $q_r(\ \cdot \ ; N_{t-\tau}, N_t)$ it is just the afore mentioned Negative-Binomial restricted to the interval $[0, N_t]$
	
	Now let's consider $S_t | N_{t-1}$ probability density:
	\begin{equation*}
	\begin{split}
	g_s(s_t | n_{t-1}) & = \int_{0}^{\infty}g_s(s_t, \epsilon_t | n_{t-1})\ \mathrm{d}\epsilon_t \\
	& = \int_{0}^{\infty}g_s(s_t | \epsilon_t, n_{t-\tau})p(\epsilon_t)\ \mathrm{d}\epsilon_t \\
	& = \binom{n_{t-1}}{s_t}\frac{\alpha^\alpha}{\Gamma(\alpha)} \int_{0}^{\infty}e^{-\delta\epsilon_t s_t}(1-e^{-\delta\epsilon_t})^{n_{t-1}-s_t}\epsilon_t^{\alpha-1}e^{-\alpha\epsilon_t}\ \mathrm{d}\epsilon_t \\
	& = \binom{n_{t-1}}{s_t}\frac{\alpha^\alpha}{\Gamma(\alpha)}\int_{0}^{\infty}e^{-(\delta s_t+\alpha)\epsilon_t }(1-e^{-\delta\epsilon_t})^{n_{t-1}-s_t}\epsilon_t^{\alpha-1}\ \mathrm{d}\epsilon_t \\
	& = \binom{n_{t-1}}{s_t}\frac{\alpha^\alpha}{\Gamma(\alpha)}\sum_{k=0}^{n_{t-1}-s_t}\binom{n_{t-1}-s_t}{k}(-1)^k \ \int_{0}^{\infty}e^{-(\delta s_t+\alpha + k\delta)\epsilon_t }\epsilon_t^{\alpha-1}\ \mathrm{d}\epsilon_t \\
	& = \binom{n_{t-1}}{s_t}\alpha^\alpha\sum_{k=0}^{n_{t-1}-s_t}\binom{n_{t-1}-s_t}{k}\frac{(-1)^k}{(\delta(s_t+k)+\alpha)^\alpha}
	\end{split}
	\end{equation*}
	where $\alpha = \sigma_d^{-2}$
	We thus have a close form for $g_s(s_t | n_{t-1})$ but it is not the density of a known distribution.
	
	As for $q_s(\ \cdot \ ; N_{t-1}, N_t)$ we can notice that if $e^{-\epsilon_t}$ were Beta distributed then $q_s(\ \cdot \ ; N_{t-1})$ would be a Beta-Binomial and $q_s(\ \cdot \ ; N_{t-1}, N_t)$ would be the same distribution but restricted to the interval $[0, N_t]$. 
	
Notice that $e^{-\epsilon} \in ]0, 1]$. So it's the support of a Beta. Natural idea is to minimize the KL divergence between the distribution of $e^{-\epsilon}$ (we know its density its just an easy change of variable) and a Beta. 
If we denote $P=e^{-\epsilon}$ and $q_P(p)=\frac{\beta^\alpha}{\Gamma(\alpha)}(-\log p)^{\alpha-1}p^{\beta-1}$ its density and if we denote $q(\ \cdot \ ; a, b)$ the density of a $\mathrm{Beta}(a,b)$ we have:

\begin{equation*}
\begin{split}
D_{KL}(a,b) & = \int_{0}^{1}q_P(p)\frac{q_P(p)}{q(p; a, b)}\mathrm{d}p \\
& \propto - \int_{0}^{1}q_P(p)\log(q(p; a, b))\mathrm{d}p \\
& \propto - \int_{0}^{1}q_P(p)\log(\frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)}p^{a-1}(1-p)^{b-1})\mathrm{d}p \\
& \propto -\log\Gamma(a+b) + \log\Gamma(a) + \log\Gamma(b) \\ & \qquad  + (a-1)\int_{0}^{1}(-\log p)\frac{\beta^\alpha}{\Gamma(\alpha)}(-\log p)^{\alpha-1}p^{\beta-1}\mathrm{d}p \\ & \qquad - (b-1)\int_{0}^{1}\log (1-p)\frac{\beta^\alpha}{\Gamma(\alpha)}(-\log p)^{\alpha-1}p^{\beta-1}\mathrm{d}p
\end{split}
\end{equation*}

Now notice that $-\log p(-\log p)^{\alpha-1}p^{\beta-1}= (-\log p)^{\alpha}p^{\beta-1}$ is proportional to the density of $e^{-X}$ where $X \sim \mathrm{Gamma}(\alpha+1, \beta)$ and if we denote $K=\int_{0}^{1}\log(1-p)\frac{\beta^\alpha}{\Gamma(\alpha)}(-\log p)^{\alpha-1}p^{\beta-1}\mathrm{d}p$ we have:

\begin{equation*}
\begin{split}
D_{KL}(a,b) & = \propto -\log\Gamma(a+b) + \log\Gamma(a) + \log\Gamma(b) \\ 
& \qquad  + (a-1)\frac{\beta^\alpha}{\Gamma(\alpha)}\frac{\Gamma(\alpha+1)}{\beta^{\alpha+1}} - (b-1)K \\
& \propto -\log\Gamma(a+b) + \log\Gamma(a) + \log\Gamma(b) + (a-1)\frac{\alpha}{\beta} - (b-1)K
\end{split}
\end{equation*}

Now we minimize by finding a critical point:
\begin{equation}
\frac{\partial }{\partial a}D_{KL} = -\psi^{(0)}(a+b) + \psi^{(0)}(a) + \frac{\alpha}{\beta} = 0
\end{equation}
\begin{equation}
\frac{\partial }{\partial b}D_{KL} = -\psi^{(0)}(a+b) + \psi^{(0)}(b) - K = 0
\end{equation}
where $\psi^{(0)}$ is the digamma function.
$K$ is easily calculated numerically and so is the system of two equations above

This critical point is indeed a minimum since 
\begin{equation}
\frac{\partial^2 }{\partial a^2}D_{KL} = -\psi^{(1)}(a+b) + \psi^{(1)}(a)
\end{equation}
\begin{equation}
\frac{\partial^2 }{\partial b^2}D_{KL} = -\psi^{(1)}(a+b) + \psi^{(1)}(b)
\end{equation}
where $\psi^{(1)}$ is the trigamma function. 
These two functions are always negative as $\psi^{(1)}$ is strictly non increasing and $a, b > 0$.

I did a numerical example with  $\alpha = \beta = 10$ and found $a = 6.739281$ and $b=10.736471$. I sampled 10000 times from $e^{-\epsilon}$ and the Beta with coefficient $a$ and $b$ and  the QQ-plot shown in Figure~\ref{fig:qq} seems to indicate that the approximation is accurate

\begin{figure}[htb]
	\centering
	\includegraphics[width=0.97\linewidth]{/home/raphael/dissertation/figures/approxbeta.pdf}
	\caption{QQ plot comparing the Beta approximation and $e^{-\epsilon}$}
	\label{fig:qq}
\end{figure}

\clearpage
\end{document}