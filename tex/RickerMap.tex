\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[fleqn]{amsmath}
\usepackage[T1]{fontenc}
\usepackage{parskip}
\usepackage{booktabs}
\usepackage{mathtools}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{natbib}
\usepackage{textcomp}
\usepackage{booktabs}
\usepackage{pgfplots}
\usepackage{pgfplotstable}
\usepackage{array}
\usepackage{bbold}
\usepackage{amssymb}
\usepackage[procnames]{listings}
\usepackage{color}
\usepackage{graphicx}
\graphicspath{ {figures/} }
\usepackage{titlesec}

\usepackage{algorithm}
\usepackage[noend]{algpseudocode}

\makeatletter
\newcommand{\distas}[1]{\mathbin{\overset{#1}{\kern\z@\sim}}}%
\newsavebox{\mybox}\newsavebox{\mysim}
\newcommand{\distras}[1]{%
	\savebox{\mybox}{\hbox{\kern3pt$\scriptstyle#1$\kern3pt}}%
	\savebox{\mysim}{\hbox{$\sim$}}%
	\mathbin{\overset{#1}{\kern\z@\resizebox{\wd\mybox}{\ht\mysim}{$\sim$}}}%
}
\makeatother

\makeatletter
\def\BState{\State\hskip-\ALG@thistlm}
\makeatother
\newcommand{\ra}[1]{\renewcommand{\arraystretch}{#1}}
\setcounter{secnumdepth}{4}

\titleformat{\paragraph}
{\normalfont\normalsize\bfseries}{\theparagraph}{1em}{}
\titlespacing*{\paragraph}
{0pt}{3.25ex plus 1ex minus .2ex}{1.5ex plus .2ex}

\title{Monte Carlo Methods for Bayesian Inference on Two Population
	Dynamics Models: The Ricker Map and Nicholson's Sheep Blowfly Experiments}
\date{}

\begin{document}
	\maketitle 
	\thispagestyle{empty}
	\begin{center}
		\vspace{-5mm}
		\includegraphics[scale=1]{logo.png} \\
		\vspace{20mm}
		{\large Raphaël Lopez-Kaufman} \\
		\vspace{2mm}
		{\large Oriel College, University of Oxford} \\
		\vspace{40mm}
		A dissertation submitted in partial fulfilment of the requirements for the degree of \\
		\vspace{1mm}
		\textit{Master of Science in Applied Statistics} \\
		\vspace{1mm}
		Trinity 2015
	\end{center}
	
	\vspace{25 mm}
	\definecolor{keywords}{RGB}{255,0,90}
	\definecolor{comments}{RGB}{0,0,113}
	\definecolor{red}{RGB}{160,0,0}
	\definecolor{green}{RGB}{0,150,0}
	
	\begin{abstract}
		In this paper, I study and modelise the time series dynamics of the Chicago Board Options Exchange Volatility Index (VIX) through Bayesian estimation of one-factor and stochastic volatility models. Markov Chain Monte Carlo techniques including Metropolis-within-Gibbs are adopted to surmount computational hurdles typical of high-dimensional diffusion model estimation and to enable the use of the Deviance Information Criterion (DIC) in model comparison. Further, High Frequency Augmentation (HFA) -- a form of Data Augmentation -- is adopted, with diffusion bridges formed between all observations in order to decrease the discretisation bias inherent in diffusion model estimation. For model assessment, I utilise posterior predictive p-values simulations and DIC tests to assess and compare the estimated non-affine one-factor and stochastic volatility models, both of which include mean reversion and price-dependent jump components. The techniques utilised and models tested are relatively new to the field of implied volatility research -- the model specifications considered in this paper and the use of DIC are unprecedented, while HFA and posterior predictive p-value simulations have been employed only once prior to this study. Applying the above-mentioned techniques, I find strong support for the inclusion of stochastic volatility, mean reversion and price-dependent jump components in a non-affine framework to ensure accurate model specification when modelising implied volatility time series.
	\end{abstract}
	
	\newpage
	\vspace*{80mm}
		\textit{I would like to express my gratitude to my academic supervisors Professor Arnaud Doucet and Doctor Lawrence Murray from University of Oxford for their time and guidance}
	
	\newpage
	
	\listoffigures
	\clearpage
	\listoftables
	\clearpage
	\tableofcontents
	
	\clearpage
	\section{Introduction}
	The study of population dynamics, either by ecologists or epidemiologists, often requires the use of elaborate methods. For example, King et al.~\cite{king2008inapparent} and Bhadra et al.~\cite{bhadra2011malaria} studied the spread of epidemics, cholera and malaria, both using iterated filtering for parameter inference of state space models~\cite{ionides2006inference}. The necessity to design such complex inference strategies arises as a consequence of the fact that most of the time population dynamics models are chaotic, or nearly chaotic resulting in multidimensional and multimodal likelihoods. Therefore traditional inference based on numerical methods to find maximum likelihood estimates do not yield satisfactory results. Chaotic behaviour in ecological and epidemiological system is not only of theoretical interest as practical examples abound (see Kausrud et al.~\cite{kausrud2008linking} on lemmings and Anderson et al.~\cite{anderson2008fishing} on fish). \\
	
	Bayesian approaches to inference have become increasingly popular with the recent improvements in computing power. Particle Markov Chain Monte Carlo Methods (PMCMC)~\cite{andrieu2010particle}, which combine a standard Markov Chain Monte Carlo (MCMC) and Sequential Monte Carlo (SMC) algorithms has become a method of choice for inference on such difficult models (see Losa et al.~\cite{losa2003sequential}, Dowd~\cite{dowd2006sequential} and Jones et al.~\cite{jones2010bayesian} for examples in marine ecology). \\
	
	Another recent type of approach, termed likelihood-free or Approximate Bayesian Computation (ABC), and first described by Rubin~\cite{rubin1984bayesianly} has also become popular (see Butler et al.~\cite{butler57latent} for an example in ecology, Tanaka et al.~\cite{tanaka2006using} in epidemiology and Thornton et al.~\cite{thornton2006approximate} in biology). This method consists in simulation from the likelihood when it is impossible to evaluate it, even point wise, as is required in PMCMC. Techniques combining MCMC and ABC (ABC-MCMC) or SMC and ABC (ABC-SMC) to sample from the posterior distribution of the parameters of such models are described respectively in Marjoram et al.~\cite{marjoram2003markov} and Toni et al.~\cite{toni2009approximate}. For a complete review see Marin et al.~\cite{marin2012approximate}. \\
	
	We studied two very famous examples of chaotic population dynamics models from ecology and performed bayesian inference on the parameters of these models using respectively a Particle Marginal Metropolis Hastings (PMMH) sampler as described in Adrieu et al.~\cite{andrieu2010particle}, which is one of the PMCMC algorithms, and a ABC-MCMC sampler. The first model is a noisily observed version of the Ricker map described by Wood~\cite{wood2010statistical} whereas the second one is a solution to the stochastic differential equation suggested by Gurney et al.~\cite{gurney1980nicholson} and Nisbet et al.~\cite{nisbet1982modelling} to describe the last three replicates of the four runs of Nicholson’s classic experiments on sheep blowfly~\cite{nicholson1954outline}~\cite{nicholson1957self}.
	
	In section 1 of this dissertation a overview of the mathematical background needed to understand the difficulties intrinsic to these two population dynamics models will be given. Section 2 describes the statistical methods used to perform bayesian inference on these two models along with the theoretical reasons, advantages and disadvantages of doing so. Section 3 is dedicated to the actual algorithms that were implemented. Section 4 presents the results attained and contrast them with those obtained by Wood~\cite{wood2010statistical}. Finally a conclusion and a discussion on the merits and limitations of the methods presented is given in the last section.
	
	\section{Two ecological models}
	\subsection{The Ricker Map} 
	\subsubsection{The Deterministic Ricker Map}
	The Ricker map is a difference equation used to describe the population dynamics of a wide range of ecological populations. It was first described in a seminal paper by Ricker~\cite{Ricker1954} to account for fish population sizes in fisheries. \\
	If we denote by $N_t$ the size of a population a time $t$, Ricker established that if:
	\begin{itemize}
		\item the average offspring size per individual per unit time is a constant number $r > 0$
		\item there is a crowding effect which reduces by a factor $e^{-\frac{N_t}{K}}$ the offspring size where $K > 0$
		\item generations do not overlap
	\end{itemize}
	then 
	\begin{equation}
		N_{t+1} = r N_t e^{-\frac{N_t}{K}} = f(N_t)
		\label{eq:ricker}
	\end{equation}
	The fact that generations do no overlap, which is generally a strong assumption in biology, is acceptable in the case of seasonally breeding populations, which are widespread in ecology. \\
	This model has very complex dynamics depending on the values of the parameter $r$. It has become a classic discrete population model, and although not taking into account any of the exterior factors which influence greatly ecological populations (such as destruction of natural ecosystems, pervading pollution, etc ...), it provides an accurate description of many experimental population dynamics (see Krkovsek et al. ~\cite{krkovsek2007declining} or Mueter et al.~\cite{mueter2002opposite} for applications of this model to salmon populations and Gao et al.~\cite{gao2012bayesian} to sixteen representative species from the Global Population Dynamics Database (GPDD)). \\
	
	To understand why estimating the parameters of this model given experimental data is not trivial, we first describe its chaotic behaviour. Equation~\ref{eq:ricker} has two equilibria, $N_{eq, 1} = 0$ and $N_{eq, 2} = K\log r$, which are the solutions of  $N_{eq} = r N_{eq} e^{-\frac{N_{eq}}{K}}$. Linearisation around these two equilibria, give $N_{t+1} - N_{eq, 1} = r(N_{t} - N_{eq, 1})$ and $N_{t+1} - N_{eq, 2} = (1-\log r)(N_{t} - N_{eq, 1})$. Therefore $N_{eq, 1}$ is stable when $0 < r < 1$ and unstable when $r > 1$ and $N_{eq, 2}$ is stable when $1 < r < e^2$ and unstable when $r < 1$ or $r > e^2$. The corresponding bifurcation diagram, with $K$ fixed and equal to 1, is shown in Figure~\ref{fig:stability}. Figure~\ref{fig:stab} shows the convergence towards these two equilibria for respectively $r=0.5$ and $r=3$, with $K=10$ in both cases. It can be noticed that the non zero equilibrium value is close to its theoretical value of $10 \log 3 = 10.9$. \\
	Another interesting characteristic of this map, from an ecological point of view, and the reason why it was so widely adopted, resides in the fact that it accounts for scenarii where populations oscillates before reaching an equilibrium. Figure~\ref{fig:oscill} shows such a scenario.\\
	
	Furthermore, the Ricker Map exhibits another remarkable feature. Indeed, when $r$ exceeds $e^2$ there are no stable equilibrium consisting of a single value. After a transient period, population size starts oscillating among a fixed and finite number of distinct values. The set of these values is called the \emph{orbit}. These values are the fixed points of the equation $f^n(N_t) = N_t$ with $n \in \mathbb{N^*}$ and where $f^n = \underbrace{f\circ f\circ \cdots \circ f}_{n\text{\ times}}$. When $r=e^2$ the orbit consists of 2 values, then of 4 then of 8 and so on until a critical value above which solutions follow an aperiodic pattern. $e^2$ is called a \emph{bifurcation value}, and this geometric progression in the length of the cycles is called a \emph{period doubling cascade}. Figure~\ref{fig:stability} represents the orbit as $r$ grows ($K$ is fixed and equal to 1) and was obtained experimentally. It can be seen that when $r=e^2$ the orbit consists of 2 values and of 8 when $r=2e^2$. Figure~\ref{fig:oscill} shows such an orbit of four values.
	
	As $r$ continues growing, we rapidly reach a situation where population size does not enter any stable orbit any more. This leads to a behaviour characteristic of chaos, where a small change in the value of the parameters or the initial conditions leads to very different solutions. Figure~\ref{fig:chaos} shows the evolution of two populations when either parameter $r$ or initial conditions present a very minor change. It can be noted that populations sizes, in both cases, diverges rapidly from one another.
	
	\subsubsection{The Noisily Observed Ricker Map}
	\label{NRM}
	In order to allow for external and internal stochasticity~\cite{wang2007latent} and to take into account the observational process~\cite{calder2003incorporating} (for example a counting process of salmons in fisheries), extensions to the deterministic case have been suggested. We chose to proceed with the following model, suggested by Wood (2010)~\cite{Wood2010}.
	\begin{align}
	& N_t = r N_t e^{-N_t+Z_t} \hspace{1cm} Z_t \distas{\mathrm{iid}} \mathrm{N}(0, \sigma^2) \label{noisyRickerState}\\
	& Y_t = \mathrm{Poisson}(\phi N_t)
	\label{noisyRickerObservation}
	\end{align}
	Therefore, $N_t \sim \log\mathcal{N} (\log{(rN_{t-1}e^{-N_{t-1}})},\sigma^2)$, i.e $N_t$ is log-normally distributed with parameters depending on $r$, $K$ and $\sigma$. \\
	
	This models belongs to the framework of state space models which have been widely used to describe population dynamics~\cite{lillegaard2008estimation}~\cite{zhang2009spatial}~\cite{zhang2010computational} as it allows for great flexibility, encompassing models ranging from linear gaussian to highly non-linear and non-gaussian. 
	
	The statistical problem at hand is to estimate the joint probability of $(r, K, \sigma, \phi)$ in order to determine which of the regimes described earlier drives the observed population. Due to the chaotic dynamics of the Ricker map, estimating these coefficients with precision is important if one wants to obtain simulations exhibiting the same properties as experimental data. However, such an erratic behaviour leads to a highly multimodal likelihood and traditional approaches do not suit this parameter estimation problem. \\
	Moreover, even if the map were not chaotic, the likelihood is a highly dimensional integral over $N_{0:T}$ (for ease of notation we denote $N_{0:T} \coloneqq \{N_0, N_1, \cdots, N_T\}$). Indeed we have:
	\begin{equation}
		L(y_{1:T}; \phi, r, \sigma) = \int_{0}^{\infty}p(y_{1:T}, n_{0:T} | \phi, r, \sigma)\mathrm{d}n_{0:T}
	\end{equation}
	and $T$ is ranges typically from 30 to several hundreds. Therefore classic numerical integration tools, or Markov Chain Monte Carlo algorithms which require calculation, up to a constant, of the likelihood, are not suited for this problem. Therefore a wealth of techniques have been designed solve this problem: iterated filtering~\cite{ionides2006inference}, data cloning~\cite{lele2007data} and adaptative PMCMC~\cite{peters2010ecological}.
	
	\subsection{Nicholson's experiment on Sheep Blowflies}
	
	\clearpage
	\section{Inference Methods}
	\subsection{State Space Model}
	State space models describe sets of processes which can be decomposed into the following form where $\mathrm{X}=\{x_t ; t \in \mathbb{N}\}$ is a discrete time with $x_t \in \Omega_s$ and $\mathrm{Y}=\{y_t ; t \in \mathbb{N^*}\}$ is another discrete time process with $y_t \in \Omega_o$, $\Omega_s$, $\Omega_o$ being samples spaces. The $x_t$'s are unobserved and are called the \emph{hidden states} and the $y_t$ are the \emph{observations}. Moreover, $\theta$ is a vector of parameters on which both the distribution of $\mathrm{X}$ and $\mathrm{Y}$ depend. For the purposes of this dissertation, $\Omega_s, \Omega_o \subseteq \mathbb{R}$ and $\theta \in \mathbb{R}^k$, $k \in \mathbb{N^*}$. This can be summarized as follow: 
	\begin{align}
		& p(x_0, \theta) \\
		& p(x_t | x_{t-1}, \theta) \hspace{1cm} t \ge 1\\
		& p(y_t | x_t, \theta) \hspace{1cm} t \ge 1
	\end{align}
	Note that we denote by $p(x_t)$ both the probability density of $X_t$ and its distribution if it exists, with respect to an underlying measure $\lambda$. This set of equations means that $X_t$ is a Markov process of initial distribution $p(x_0)$ and transition distribution $p(x_t | x_{t-1})$ and that the observations $y_t$ are assumed to be independent conditionally on $\{x_t ; t \in \mathbb{N}\}$, i.e $p(y_1, \cdots, y_t | x_0, \cdots, x_t) =p(x_0)\Pi_{k=1}^t p(y_k | x_k)$ where $p(y_k | x_k)$ is the marginal distribution of $y_k$. We can therefore decompose the full joint density as follows:
	\begin{align}
	\underbrace{p(x_{0:T}, y_{0:T}, \theta)}_{\text{joint}} & = \underbrace{p(x_{0:T}, \theta)}_{\text{prior}}\underbrace{p(y_{1:T}| x_{0:}, \theta)}_{\text{likelihood}} \\
		& = p(\theta)p(x_0| \theta)\prod_{k=1}^{T}p(x_k|x_{k-1}, \theta)\prod_{k=1}^{T}p(y_k|x_k, \theta)
	\end{align}\\
	
	\subsubsection{Inference on State Space Models}
	Bayesian inference on state space models consists in obtaining, conditioned on a particular dataset $y_{1:T}$, the \emph{posterior distribution} $p(x_{0:T}, \theta| y_{1:T})$. This task is divided between \emph{parameter estimation}, i.e obtaining $p(\theta | y_{1:T})$  and \emph{state estimation}, i.e obtaining $p(x_{0:T}|y_{1:T}, \theta)$. \\
	Traditional methods used for bayesian inference, such as Metropolis-Hastings and Gibbs sampling are, in most of the cases, not usable as the posterior distribution and the transition density are not known distributions and even seldom have closed forms (which precludes computation of the Metropolis Hastings acceptance ratio and of the full conditional distributions in Metropolis Hastings within Gibbs). Examples of this situation abound~\cite{beskos2006exact}~\cite{fearnhead2008particle}~\cite{murray2011particle}. Even if these closed forms were available, states are usually strongly correlated and are also often correlated with model parameters. In this case, both Metropolis Hasting and Gibbs samplers are known to perform poorly~\cite{van2011partially}. \\

	
	\paragraph{Parameter estimation}
	In both of the population dynamic models presented earlier, the aim is to perform parameter estimation so as to understand which regime the population at hand is in, and to be able to carry out simulations. \\
	To achieve this the marginal Metropolis Hastings algorithm~\cite{hastings1970monte}, combined with methods to obtain samples from  $p(x_{0:t}| y_{1:t}, \theta)$ and to calculate unbiased estimates of the likelihood, is a method of choice. \\
	This algorithm samples in fact from $p(\theta, x_{0:T} | y_{1:T})$ and is a otherwise a simple Metropolis Hastings (MH) sampler. The proposal, which matches the structure of $p(x_{0:T}, \theta | y_{1:T})$ is of the form: $q((\theta^*, x_{0:T}^*) | (\theta, x_{0:T})) = q(\theta^* | \theta)p(x_{0:T}^* | y_{1:T}, \theta^*)$ and the acceptance ratio of the MH algorithm is: 
	\begin{align*}
	\frac{p(\theta^*, x_{0:T}^* | y_{1:T})q(\theta^ | \theta^*)p(x_{0:T} | y_{1:T}, \theta)}{p(\theta, x_{0:T} | y_{1:T})q(\theta^* | \theta)p(x_{0:T}^* | y_{1:T}, \theta^*)} & = \frac{p(\theta^* | y_{1:T})q(\theta | \theta^*)}{p(\theta | y_{1:T})q(\theta^* | \theta)} \\
	& = \frac{p(y_{1:T} | \theta^*)p(\theta^*)q(\theta | \theta^*)}{p(y_{1:T}|\theta)p(\theta)q(\theta^* | \theta)}
	\end{align*}
	
	It can be noted that the terminology comes from the fact that the ratio seems to be targeting $p(\theta | y_{1:T})$.
	
 	When the relationship between states and the one between states and observations are linear and gaussian, Kalman (1960)~\cite{Kalman1960} designed a method which allows to sequentially calculates the \emph{filtering distribution}, i.e $p(x_{t}| y_{1:t}, \theta)$, which in this particular case has a closed form. From there, it is easy to recover the likelihood marginalised over $x_{0:T}$ and to sample from $p(x_{0:t}| y_{1:t}, \theta)$. In this case the proposal $q(x_{0:t}| y_{1:t}, \theta)$ Although variants of this original filter, which deal with non-linear and non-gaussian state space miodels, have been designed, such as the extended~\cite{McElhoe1966} and unscented~\cite{Julier1997} Kalman filters, they give biased estimates of $p(x_t|y_{1:t}, \theta)$. \\
 	
 	In these non-linear, non-gaussian cases, the \emph{particle filter}~\cite{Gordon1993}, which is of the family of Sequential Monte Carlo (SMC) methods, provides estimates of $p(y_{1:T}, \theta)$ and of $p(x_{0:T}|y_{1:T}, \theta)$ which, when used as the proposal distribution, leaves invariant $p(x_{0:T}, \theta|y_{1:T})$ and ensures that the marginal Metropolis Hastings sampler is ergodic. This version of the algorithm is commonly referred to as the Particle Marginal Metropolis Hastings (PMMH) sampler and is described, along with the proof that it is indeed ergodic under mild assumptions in Andrieu et al.~\cite{andrieu2010particle}.
	
	\subsubsection{Particle Filter}
	We describe a little further the particle filter as it is the method we applied in order to estimate the likelihood and sample from $p(x_{0:T}|y_{1:T}, \theta)$ to carry out parameter inference in the case of the noisily observed Ricker map. \\
	This method is based on sequential importance sampling.
	The idea behind importance sampling is to approximate $p(x_{1:t}|y_{1:t}, \theta)$ with the empirical distribution
	\begin{equation}
	\hat{p}(x_{0:t}|y_{1:t}, \theta) = \sum_{i=1}^{N}\tilde{w}_t^{(i)} \delta_{x_{0:t}^{(i)}}(x_{0:t})
	\end{equation}
	where $\tilde{w}_t^{(i)} = \frac{W(x_{0:t}^{(i)})}{\sum_{j=1}^{N} W(x_{0:t}^{(j)})}$ and $W(x_{0:t}) = \frac{p(x_{1:t},y_{1:t}, \theta)}{q(x_{1:t})}$ where $x_{0:t}^{(i)}$ are iid draws from $q(x_{1:t})$, which is an easy to sample from distribution.
	
	However, this method does not take advantage of dependency structure of the state space model. Indeed, the weights $W(x_{0:t})$ can be expressed sequentially using the fact that the $y_t$ are conditionally independent given $x_{0:t}$ and that the $x_t$ have the Markov property. Moreover a choice of proposal distribution which also has the Markov property (i.e $q(x_{1:t})=q(x_{1:t-1})q(x_t| x_{t-1})$) allows us to write:
	\begin{align}
		W(x_{0:t}) & = \frac{p(x_{0:t},y_{1:t}, \theta)}{q(x_{0:t},y_{1:t}, \theta)} \\
		& = p(y_t|x_t)p(x_t|x_{t-1})
	\end{align}
	
	If we take any bounded measurable function $\phi$ Geweke (1989)~\cite{Geweke1989} showed, under certain conditions, that \begin{equation*}
		 \mathrm{I_N^{IS}}=\mathbb{E_{\hat{p}}}\phi(x_{0:t}) = \sum_{i=1}^{N} \tilde{w}_t^{(i)} \phi(x_{0:t}^{(i)}) \xrightarrow{\mathrm{a.s}} \int_{\Omega^n} \phi({x_{0:t}})p(x_{0:t}|y_{1:t})\mathrm{d}x_{0:t}=\mathbb{E_{{p}}}\phi(x_{0:t})
	\end{equation*}
	and moreover that the bias and the variance are $\mathcal{O}(\frac{1}{N})$.\\
	
	However, as shown in ~\cite{kong1994sequential}, the variance of the weights is exponential in the number $n$ of time steps. Moreover, the effective sample size (ESS), as defined in ~\cite{liu2008monte} pp 35-36, which measures the ratio between the variance of $\mathrm{I_N^{IS}}$ and of the same quantity if the samples were independently drawn from the true distribution, vanishes quickly.  
	
	The idea introduced by particle filters is to introduce resample moves. This consists in sampling, at each time step, from the importance sampling approximation $\hat{p(x_{0:t}|y_{1:t}, \theta)}$. This is achieved by selecting $x_{0:t}^{(i)}$ with probability $\tilde{w_n}^{(i)}$. Since sequential importance sampling propagates $N$ particles, this resample move is performed $N$ times at each time step. If $N_n^{(i)}$ is the number of offspring of each particle $x_{0:t}^{(i)}$, the final approximation of the target obtained is 
	\begin{equation*}
	 	\hat{p}(x_{0:t}|y_{1:t}, \theta) = \sum_{i=1}^{N}\frac{N_t^{(i)}}{N} \delta_{x_{0:t}^{(i)}}(x_{0:t})
	\end{equation*}
	Resampling has the beneficial effect to make the weights more balanced by removing samples far from regions of high density of the target distribution. Moreover, at each time step, the propagated particles are drawn from $\hat{p}(x_{0:t}|y_{1:t}, \theta)$ which leads to approximate the target by a series of closer and closer targets, from $\hat{p}(x_0|\theta)$ to $\hat{p}(x_{0:T}|y_{1:T}, \theta)$.
	 
	Using the fact that $p(y_{1:T}| \theta) = p(y_1|\theta)\prod_{k=2}^{T}p(y_k|y_{1:k-1}, \theta)$ and that \\
	$p(y_k|y_{1:k-1}, \theta) = \frac{1}{N}\sum_{i=1}^{N}W_k^{(i)}$ we have $\hat{p}(y_{1:T}| \theta)=\frac{1}{N}\prod_{k=1}^{T}\sum_{i=1}^{N}W_k^{(i)}$. It can be shown (see~\cite{del2004feynman}) that $\hat{p}(y_{1:T}| \theta$ is an unbiased estimate of the likelihood and we saw earlier that the particle filter allows to draw from an estimate (converging in distribution to) of $p(x_{0:T}|y_{1:T}, \theta)$, which are the quantities needed to make us of the PMMH sampler. For more details on SMC methods and the particle filter see~\cite{doucet2009tutorial} and for more details on resampling and its complexity see~\cite{murray2013parallel}.
	
	\section{Inference on the noisily observed Ricker Map}
	\subsection{Algorithm}
	In order to perform inference on the noisily observed Ricker Map, we used a PMMH sampler along with particle filter. \\
	We restate here the state space model, given in~\ref{NRM}, which is used to describe this population dynamics model.
	\begin{align}
	& N_t = r N_t e^{-N_t+Z_t} \hspace{1cm} Z_t \distas{\mathrm{iid}} \mathrm{N}(0, \sigma^2)\\
	& Y_t = \mathrm{Poisson}(\phi N_t)
	\end{align}
	
	\subsubsection{Particle Filter} \label{pfRIcker}
	Theoretical results indicate that the proposal density to use in order to minimize the variance of the likelihood estimate is $p(n_t | y_t, n_{t-1})$. However we have $p(n_t | y_t, n_{t-1}) \propto p(y_t|n_t)p(n_t|n_{t-1})$ where $p(y_t|n_t)$ is a Poisson distribution and $p(n_t|n_{t-1})$ a log normal distribution. This does not yield a known distribution from which we could sample. However, the conjugate distribution of a Poisson is a Gamma distribution. Therefore approximating the transition density with a Gamma distribution yields a Gamma proposal which is, hopefully, close enough from the true optimal proposal distribution. \\
	
	In order to approximate a Lognormal distribution with the closest Gamma distribution, we chose to minimize the Kullback-Liebler (KL) divergence~\cite{kullback1951information} between these two distributions. Indeed, the KL divergence measure the information for discrimination between two hypothesis regarding the population from which as sample is drawn. In a nutshell it means that the smaller is this divergence, the closer two probability measures are. Here we aim to minimize:
	\begin{equation}
	D_{KL}(P||Q)(\alpha, \beta) = \int_{0}^{\infty}{p(z|\mu, \sigma^2)\log(\frac{p(z|\mu, \sigma^2)}{q(z|\alpha, \beta)})\mathrm{d}z}
	\end{equation}
	where $p$ is the probability density function of a $\log\mathcal{N}(\mu, \sigma^2)$ and $q$ of a Gamma with shape $\alpha$ and scale $\beta$. Minimization finding critical points of the divergence give, $\alpha =\frac{1}{\sigma^2}$ and $\beta=\frac{1}{\alpha}e^{\mu+\frac{\sigma^2}{2}}$, and in the specific case of our state space model $\alpha(n_{t-1})= \frac{1}{\sigma^2}$ and $\beta(n_{t-1})=\sigma^2e^{\log(rn_{t-1}e^{-n_{t-1}})+\frac{\sigma^2}{2}}$. See~\ref{KLRicker} for details. \\
	We thus approximate the transition density at each time step $t$ with:
	\begin{equation*}
	q(n_t|\alpha(n_{t-1}), \beta(n_{t-1}), \theta) = \mathrm{Gamma}(\ \cdot \ ; \alpha(n_{t-1}), \beta(n_{t-1}) )
	\end{equation*}
	This leads us to the following proposal for the particle filter:
	\begin{equation*}
	\begin{split}
	q(n_t|n_{t-1}, y_t, \theta) & \propto  p(y_t|n_t, \theta)q(n_t|n_{t-1}, \theta) \\
	& \propto e^{-\phi n_t}(\phi n_t)^{y_t}n_t^{\alpha(n_{t-1})-1}e^{-\frac{n_t}{\theta(n_{t-1})}}
	\end{split}
	\end{equation*}
	i.e:
	\begin{equation*}
	q(n_t|n_{t-1}, y_t, \theta) = \mathrm{Gamma}(\ \cdot \ ; y_t+\alpha(n_{t-1}), \frac{\beta(n_{t-1})}{\beta(n_{t-1})\phi + 1})\end{equation*} \\
	
	We chose to use a multinomial resampler in our particle filter and chose to resample at each time step. The pseudo-code of the algorithm we used for the particle filter is given in Algorithm~\ref{pf}. It returns samples from $p(x_t | y_{1:t}, \theta)$, estimates of the log-likelihood $\hat{l}_t$ and the effective sample size $\mathrm{ESS}_t$ at each time step. \\
	This algorithm was implemented in Python, using Numpy/Scipy to simulate from known random variables and Cython to speed up critical code~\cite{wilbers2009using, behnel2011cython} (such as density calculations). Simulation showed that Numpy implementation of multinomial and gamma sampling were linear in the number of particle $N$. The rests of the calculations (weight, ESS, likelihood, parameters of the proposal distribution) are also linear in the number of particle. As for space complexity, one estimate of the filtering distribution is stored and each time step, along with the likelihood estimate and the ESS. Therefore the space complexity is linear in the number of steps $T$. Experimental simulations, shown in Figure~\ref{runningRicker}, for a number of particle varying from 10 to 10000, of the running time of Algorithm~\ref{pf} averaged over 100 repetitions, confirms an average running time of $\mathcal{O}(N)$.
	
	\subsubsection{Particle Marginal Metropolis Hastings Sampler}
	Algorithm~\ref{pmmh} shows the straightforward implementation of the PMMH sampler we used. At each time step a new set of parameter is proposed using a multivariate random walk whose components are independent. We chose independence as we did not have any information on the correlation structure of the vector of parameters. Following Wood~\cite{fasiolo2014statistical} we also chose independent uniform priors on the parameters. \\
	
	After a burnin period, we adapt the covariance matrix of the proposal using the Robbins-Monro update, as described in Andrieu and Thoms~\cite{Andrieu2008}. Indeed, as proved by Roberts et al.~\cite{roberts1997weak} for a certain class of target distribution (namely those of the form $\pi_n(x) = \prod_{i=1}^{n}f(x_i)$ where $x \in \mathbb{R}^n$ and certain regularity conditions on f, the same result for other form of $\pi$ has been proved, see~\cite{roberts2001optimal}), the optimal acceptance rate, when using a multivariate random walk proposal, in term of mixing, is close to 0.234. In the case of a PMMH sampler, where the likelihood is an approximation of the true one, this rate should be decreased to 0.1~0.15 (as suggested by Dr. Lawrence Murray). This adaptation period allows us not to worry too much about the initialisation of the covariance matrix of the random walk. When adapting during the whole chain, care should be exercised regarding the convergence towards the target distribution of the MCMC algorithm. However, we chose to adapt only for a brief (although long enough to reach the targeted acceptance rate) period of time, typically 10 to 15\% of the total length of the chain.\\
	
	More specifically the Robins-Monro update is used to rescale the covariance matrix of the random walk. In the case of a univariate proposal $q_\theta \sim \mathcal{N}(0, exp(\theta))$ and target distribution $\pi$,  what adaptation aims to do is to find the zeros of $h(\theta) = \mathbb{E}_{\pi\otimes q_\theta}\mathrm{H}(\theta, x, y)$ where $\mathrm{H}(\theta, x, y) = \min(1, \frac{\pi(y)}{\pi(x)}) - \alpha^*$ and $\alpha^*$ is the target average acceptance rate. Robins-Monro update proceed iteratively by setting $\theta_{i+1} = \theta_i + \frac{1}{i+1}(\hat{\alpha}_{\theta_i} - \alpha^*)$ where $\hat{\alpha}_{\theta_i} = \frac{1}{L}\sum_{k=1}^{L}\frac{\pi(y_{iL+k})}{\pi(x_{iL+k-1})}$. If $\hat{\alpha}_{\theta_i}$ is unbiased, Robbins and Monro~\cite{robbins1951stochastic} have shown that, under certain regularity conditions on H and and $\hat{\alpha}_\theta$, $\theta_i$ converges in probability to $\alpha^*$. Here, it can be simply understood noticing that if the acceptance rate $\hat{\alpha}_\theta$ is greater than the target $\theta$ and thus the variance of the random walk is increased, leading to greater moves in the parameter space and thus a reduced acceptance rate. The contrary happens when $\hat{\alpha}_\theta$ is smaller than the target. Principled statistical rules exists to determine when to stop the adaptation phase, but, since we were targeting a range rather than a specific value for the acceptance rate,  we relied on trial and error to determine its approximate duration to reach the range 0.1-0.15. Finally, since we used a multivariate random walk with a diagonal covariance matrix, we decided to simultaneously adapt its coefficient using the Robbins-Monro update. This very simple approach proved satisfactory as all the chains we ran attained average acceptance rate within the targeted range.
	
	
	\subsection{Synthetic Data}
	In order to obtain a first assessment of the efficiency of our PMMH algorithm, and to compare our results to Wood's~\cite{fasiolo2014statistical}, we used simulated datasets from the Ricker map model. It should be noted that Wood use a slightly different version of the more general one we gave, where $K$ is set to one and is not allowed to vary. However, even though we shall conform with this definition in this section, when we use real data later on, $K$ will be again allowed to vary. As in Wood's, we chose to set $r=log(3.8)$, $\sigma=0.3$, $\phi=10$ and $T=50$ (such a short path is chosen because real data on population size is seldom longer). This places us in the  chaotic regime of the Ricker map as $log(3.8) \approx 44.7 > e^2$. \\
	
	We first compared the evolution of the effective sample size using our proposal (as described in Section~\ref{pfRIcker}) and the transition density $p(n_t|n_{t-1})$ as proposal, called \emph{prior proposal} (this version of particle filter is called \emph{bootstrap filter}) used by Wood. Figure~\ref{fig:essRicker} shows this comparison. Note that we used 500 particles in each cases. It can be seen that the use of the prior proposal leads to an extremely irregular ESS, with very sharp dips, indicative of very imbalance weights. This is due to the fact that the transition density approximates badly the successive targeted distributions. On the contrary, our gamma approximation to the optimal proposal, because it incorporates knowledge from the actual observations, is less irregular, and shows very few dips below $\frac{N}{2}$. \\
	
	We also compared the stability of the maximum likelihood estimate for $r$ (keeping $\sigma$ and $\phi$ fixed and equal to their true value) when using the prior proposal and our gamma approximation to the optimal proposal. We calculated the likelihood for $r \in [12, 90]$ using a discretisation size equal to 0.5. We repeated the experiment 50 times. The variance of the maximum likelihood estimates and the mean squared errors obtained using different numbers of particles are displayed in Table~\ref{table:mleR} where the index 1 denotes the prior proposal and index 2 our gamma approximation. Figure~\ref{fig:comparisonR}, shows the MLE obtained across the iterations using 50, 100, 200, 500, 1000 and 1500 particles. \\
	We used the same methodology for $\phi$ and $\sigma$, using respectively a discretisation path of 0.06 and 0.003 in the intervals $[5, 15]$ and $[0.15, 0.6]$. Table~\ref{fig:mlePhi}, Table~\ref{fig:mleSigma}, Figure~\ref{fig:comparisonPhi} and Figure~\ref{fig:comparisonSigma} respectively show the evolution of the variance and the mean square error of the maximum likelihood estimates and the MLE obtained across the iterations. Finally, Figure~\ref{fig:transect} shows transect of the log-likelihood with respect to $r$, $\phi$ and $\sigma$. 
	
	We performed parameter inference on this synthetic dataset using our implementation of a PMMH sampler and our gamma approximation for the particle filter responsible for the likelihood estimation. First, we sampled five chains from the same dataset, using initial values for the parameters sampled from normal distributions,  in order to perform the usual convergence and mixing diagnostic on an MCMC algorithm. Mixing is assessed via graphical inspection of the samples (traceplot). Figure~\ref{fig:traceplotDiag} shows the traceplots for each of the parameters. The parameter space seem to be satisfactorily explored and no strong correlation pattern can be seen. This is further confirmed by inspecting the autocorrelation function (ACF) of the samples, displayed in Figure~\ref{fig:acfDiag}. For each parameter the ACF decreases quickly under the significance threshold. Convergence is assessed using running means and the Gelman-Rubin diagnostic~\cite{gelman1992inference}. We denote $m_i$ such that $m_i=\frac{j=1}{i}\sum_{j=1}^{i}s_j$, where $s_i$ is the i\textsuperscript{th} sample of a chain, as the running mean of a chain. It can be seen in Figure~\ref{fig:rmDiag} that the running means converge to the same values for each parameters across the chain regardless of the initial values. This is a good indication that the samples obtained from the PMMH sampler are distributed according to the same stationary distribution. However, it is also visible that the posterior estimates are biased (for example, the posterior mean for $r$ is just below 40, whereas its true value is 44.7). Even though the likelihood estimate given by the particle filter is unbiased, it is a logic consequence of using a approximation instead of the true likelihood. \\
	The Gelman-Rubin diagnostic plots the values of $R = \sqrt{\frac{\mathrm{Var}(\alpha)}{W}}$ where $W$ is the average of the within-chain variances, where the within-chain variance is the empirical variance of the chain, and $ \mathrm{Var}(\alpha) = \frac{n-1}{n}W + \frac{1}{n}B$ where $B$ is the between-chain variance, \emph{i.e} the empirical variance of the means of the chains. $R$ should converge to one as the length of the chains increases, if, regardless of the initialization, the chains converges to the same stationary distribution. It can be seen in Figure~\ref{fig:gelmanDiag} that $R$ converges towards 1 quickly for all parameters. \\
	
	However, the aim was again to compare our results to those presented by Wood in order to see the improvement brought by our gamma approximation. Following his algorithm we used uniform priors on the parameters, each time setting the lower bound to half the true value of the parameter and the upper bound to 1.5 that of the true value. We discarded, as Wood, 2500 samples as a burnin, and set, unlike Wood this time, 2500 iterations as an adaptation phase. We set the total length of the chain to 17500 iteration so as to have the same number of samples from which to estimate the posterior distribution of the parameters as Wood, that is to say 12500 iterations. In order to compare our results, we used the same two metrics as defined by Wood. These metrics are the median squared errors for each parameters and the median and inter-quartile range of the squared errors, averaged geometrically across the parameters, that is to say of the $e_j = ((\hat{\log r}_j-\log r)(\hat{\sigma}_j-\sigma)(\hat{\phi}_j-\phi))^\frac{1}{3}$ where $j$ denotes the number of the experiment and a hat denotes a posterior mean. Note the use of $\log r$ instead of $r$. Although not specified in Wood's, it seems that the values he reports for both metrics are for $\log r$. It is probably due to the fact that the parametrisation of the Ricker map makes more often presented as $N_t = N_{t-1}e^{r(1-\frac{N_{t-1}}{K})}$. We also performed inference using LibBi which is a software package for state-space modelling and Bayesian inference~\cite{murray2013bayesian}. This well established software, which implements a PMMH sampler, which uses a bootstrap filter, among other samplers, was used to represent a reliable baseline to which we compared both our and Wood's results. Wood used 250 synthetic dataset to calculate his metrics, whereas we used only 50 due to time restrictions. \\
	Table~\ref{mse} reports the median squared errors obtained whereas Table~\ref{metric} reports Wood's custom metric. It can be seen that, apart for $\sigma$ where LibBi and our PMMH sampler give MSE an order of magnitude lower, the MSE are of the same order of magnitude across all methods. Similarly, Wood's custom metric are of the same order of magnitude across all methods.
	
	
	
	\begin{algorithm}
		\caption{Particle filter}\label{pf}
		\begin{algorithmic}[1]
			\Function{PARTICLE-FILTER}{N, T, $\theta$}
			\BState t=0: // initialization
			\ForAll{$i \in \{1, \cdots, N\}$} 
			\State Sample $N_0^{(i)} \sim q_0(n_0|\theta)$
			\State Set $w_0^{(i)} \gets \frac{1}{N}$
			\State Set $\hat{l_0} \gets 0$ // initialize log-likelihood
			\State Set $\mathrm{ESS}_0 \gets N$ // initialize ESS
			\State Set $\hat{n}_0 \gets n_0$ // initialize state
			\State Set $t \gets 1$
			\EndFor
			\item[]
			\BState $1 \le t \le T$:
			\While{$t \le T$}
			\State Sample $(a_t^{(1)}, \cdots, a_t^{(N)} \sim \mathrm{Multinomial}(w_{t-1}^{(1)}, \cdots, w_{t-1}^{(N)})$ // ancestors 
			\ForAll{$i \in \{1, \cdots, N\}$}
			\State Set $\alpha, \beta \gets \text{CALC-PARAM}(n_{t-1}, \theta)$ // proposal parameters
			\item[]
			\State Sample $n_t^{(i)} \sim q(n_t| n_{t-1}^{a_t^{(i)}}, y_t, \theta)$ // propagate particle
			\item[]
			\State Set $w_t^{(i)} \gets \frac{\strut p(n_t|n_{t-1}^{a_t^{(i)}}, \theta)}{\strut p(y_t|n_t^{(i)}, \theta)q(n_t|n_{t-1}^{a_t^{(i)}, \theta}, y_t)}$ // weight particle
			\EndFor
			\item[]
			\State $\hat{l}_t \gets \hat{l}_{t-1} - \log N + \log\sum_{i=1}^{N}w_t^{(i)}$
			\State Normalize $(w_t^{(0)}, \cdots, w_t^{(N)})$
			\State Set $\mathrm{ESS_t} \gets (\sum_{i=1}^{N}(\mathrm{W}_t^{(i)})^2)^{-1}$ // W denotes a normalized weight
			\State Set $\hat{n}_t \gets \sum_{i=1}^{N}\mathrm{W}_t^{(i)}n_t^{(i)}$
			\EndWhile
			\item[]
			\Return $\hat{l}_T$, $(\hat{n}_0, \cdots, \hat{n}_T)$,  $(\mathrm{ESS}_0, \cdots, \mathrm{ESS}_T)$
			\EndFunction
		\end{algorithmic}
	\end{algorithm}
	
	\begin{algorithm}
		\caption{Particle Marginal Metropolis Hastings Sampler}\label{pmmh}
		\begin{algorithmic}[1]
			\Function{PMMH}{N, T, $\theta_0$, filter, burnin, adaptation, samples, L}
			\State $l_0 \gets \text{filter}(N, T, \theta_0)$
			\ForAll{$i \in \{1, \cdots, \text{burnin}\}$}
			\State $\theta_i, l_i, \alpha_i \gets \text{ROUTINE}(N, T, \theta_{i-1}, l_{i-1}, \text{filter})$
			\EndFor
			\ForAll{$i \in \{\text{burnin}, \cdots, \text{adaptation}\}$}
			\State $\hat{\alpha}_\Sigma \gets 0$
			\ForAll{$j \in \{1, \cdots, L\}$}
			\State $\theta_i, l_i, \alpha_i \gets \text{ROUTINE}(N, T, \theta_{i-1}, l_{i-1}, \text{filter})$
			\State $\hat{\alpha}_\Sigma \gets \hat{\alpha}_\Sigma + \frac{1}{L}\alpha_i$
			\EndFor
			\State $\Sigma \gets \text{RESCALE}(\hat{\alpha}_\Sigma, \Sigma)$
			\EndFor
			\ForAll{$i \in \{\text{adaptation}, \cdots, \text{samples}\}$}
			\State $\theta_i, l_i, \alpha_i \gets \text{ROUTINE}(N, T, \theta_{i-1}, l_{i-1}, \text{filter})$
			\EndFor
			\Return $(\theta_{\text{adaptation}},\theta_{\text{adaptation}+1}, \cdots, \theta_{\text{samples}})$
			\EndFunction
		\end{algorithmic}
	\end{algorithm}
	
	\begin{algorithm}
		\caption{Routine for PMMH Sampler}\label{routine}
		\begin{algorithmic}[1]
			\Function{ROUTINE}{N, T, $\theta$, $l$, filter}
			\State $\theta^* \gets q_{RW}(\theta, \Sigma)$
			\State $l^* \gets \text{filter}(N, T, \theta^*)$
			\State $\alpha(\theta, \theta^*) = l^*+\log q(\theta|\theta^*) + \log p(\theta) - l - \log q(\theta^*|\theta) - \log p(\theta^*)$
			\State Sample $u \sim \text{U}([0, 1])$
			\If{$\log u \le \alpha(\theta, \theta^*)$}
			\State \Return $\theta^*$, $l^*$, $\alpha$
			\Else
			\State \Return $\theta$, $l$, $\alpha$
			\EndIf
			\EndFunction
		\end{algorithmic}
	\end{algorithm}
	
	
	\begin{figure}[htb]
		\centering
		\begin{minipage}{0.4\textwidth}
			\centering
			\includegraphics[width=0.97\linewidth]{/home/raphael/dissertation/figures/stability.pdf}
		\end{minipage}
		\begin{minipage}{0.4\textwidth}
			\centering
			\includegraphics[width=0.97\linewidth]{/home/raphael/dissertation/figures/bifucdiagram.pdf}
		\end{minipage}
		\caption{\textbf{(left)}Bifurcation diagram of the Ricker map. \textbf{Dotted} lines correspond to unstable equilibria and \textbf{solid} lines to stable ones. \textbf{(right)} Bifurcation diagram of the Ricker Map.}
		\label{fig:stability}
	\end{figure}

	\begin{figure}[htb]
		\centering
		\begin{minipage}{0.4\textwidth}
			\centering
			\includegraphics[width=0.97\linewidth]{/home/raphael/dissertation/figures/0value_ricker.pdf}
		\end{minipage}
		\begin{minipage}{0.4\textwidth}
			\centering
			\includegraphics[width=0.97\linewidth]{/home/raphael/dissertation/figures/stable_ricker.pdf}
		\end{minipage}
		\caption{Convergence towards the equilibria of the Ricker map}
		\label{fig:stab}
	\end{figure}

	\begin{figure}[htb]
		\centering
		\begin{minipage}{0.4\textwidth}
			\centering
			\includegraphics[width=0.97\linewidth]{/home/raphael/dissertation/figures/oscill_ricker.pdf}
		\end{minipage}
		\begin{minipage}{0.4\textwidth}
			\centering
			\includegraphics[width=0.97\linewidth]{/home/raphael/dissertation/figures/4values_ricker.pdf}
		\end{minipage}
		\caption{\textbf{(left)} The population size oscillates before converging towards equilibrium. \textbf{(right)} The population sizes describes an orbit of length four.}
		\label{fig:oscill}
	\end{figure}
	
	\begin{figure}[htb]
		\centering
		\begin{minipage}{0.4\textwidth}
			\centering
			\includegraphics[width=0.97\linewidth]{/home/raphael/dissertation/figures/rchange.pdf}
		\end{minipage}
		\begin{minipage}{0.4\textwidth}
			\centering
			\includegraphics[width=0.97\linewidth]{/home/raphael/dissertation/figures/initchange.pdf}
		\end{minipage}
		\caption{\textbf{(left)} Evolution of the population size when \textbf{(black)}$r=50$ and \textbf{(red)}$r=50.1$ with initial value $N_0=7$. \textbf{(right)} Evolution of the population size when \textbf{(black)}$N_0=7$ and \textbf{(red)}$N_0=7.1$ with $r=50$.}
		\label{fig:chaos}
	\end{figure}

	\begin{figure}[htb]
		\centering
		\begin{minipage}{0.4\textwidth}
			\centering
			\includegraphics[width=0.97\linewidth]{/home/raphael/dissertation/figures/runningRicker.pdf}
		\end{minipage}
		\caption{Running time of Algorithm~\ref{pf}, averaged over 100 runs, for an increasing number of particles. In \textbf{red} is shown a linear intercept of the curve.}
		\label{fig:runningRicker}
	\end{figure}

	\begin{figure}[htb]
		\centering
		\begin{minipage}{0.4\textwidth}
			\centering
			\includegraphics[width=0.97\linewidth]{/home/raphael/dissertation/figures/ESSRickerPrior.pdf}
		\end{minipage}
		\begin{minipage}{0.4\textwidth}
			\centering
			\includegraphics[width=0.97\linewidth]{/home/raphael/dissertation/figures/ESSRickerGamma.pdf}
		\end{minipage}
		\caption{\textbf{(left)} Evolution of the effective sample size using \textbf{(left)} the prior proposal, \textbf{(right)} our gamma approximation to the optimal proposal.}
		\label{fig:essRicker}
	\end{figure}
	
	\begin{figure}[htb]
		\centering
		\begin{minipage}{0.4\textwidth}
			\centering
			\includegraphics[width=0.97\linewidth]{/home/raphael/dissertation/figures/mleRickerr.pdf}
		\end{minipage}
		\begin{minipage}{0.4\textwidth}
			\centering
			\includegraphics[width=0.97\linewidth]{/home/raphael/dissertation/figures/mleRickerphi.pdf}
		\end{minipage}
		\begin{minipage}{0.4\textwidth}
			\centering
			\includegraphics[width=0.97\linewidth]{/home/raphael/dissertation/figures/mleRickersigma.pdf}
		\end{minipage}
		\caption{Transect of the log-likelihood with respect to \textbf{(top left)} $r$, \textbf{(top right)} $\phi$ and \textbf{(bottom)} $\sigma$.}
		\label{fig:transect}
	\end{figure}
	
	\begin{table}[htb]
		\centering
		\ra{1.3}
		\begin{tabular}{@{}ccccc@{}} \toprule
			Number of particles & Variance1 &  Variance2 & MSE1 & MSE2 \\ \midrule
			50 & 12.828163 &  9.675612 & 12.802 & 9.483\\ 
			100 & 10.44 & 7.99 & 10.34 & 8.19\\ 
			200 & 8.164184 & 5.214388 &  8.241 & 5.127\\ 
			500 & 4.349490 & 2.206633 & 4.825 & 2.185\\ 
			1000 & 3.490714 & 1.881224 & 3.661  & 2.228\\  \bottomrule
		\end{tabular}
		\caption{Variance and mean squared error of the maximum likelihood for r obtained using 50, 100, 200, 500, 1000 and 1500 particles}
		\label{table:mleR}
	\end{table}

	\begin{table}[htb]
		\centering
		\ra{1.3}
		\begin{tabular}{@{}ccccc@{}} \toprule
			Number of particles & Variance1 &  Variance2 & MSE1 & MSE2 \\ \midrule
			50 & 0.10 & 0.052 & 0.26 & 0.16\\
			100 & 0.054 & 0.041 & 0.18 & 0.17\\ 
			200 & 0.052 & 0.037 & 0.15 & 0.14\\ 
			500 & 0.041 & 0.025 & 0.17 & 0.14\\
			1000 & 0.021 & 0.018 & 0.17 & 0.14 \\ \bottomrule
		\end{tabular}
		\caption{Variance and mean squared error of the maximum likelihood for $\phi$ obtained using 50, 100, 200, 500, 1000 and 1500 particles}
		\label{table:mlePhi}
	\end{table}

	\begin{table}[htb]
		\centering
		\ra{1.3}
		\begin{tabular}{@{}ccccc@{}} \toprule
			Number of particles & Variance1 &  Variance2 & MSE1 ($10^{-3}$)& MSE2\\ \midrule
			50 & 2.61 & 2.32 & 2.58 & 2.51\\
			100 & 2.09 & 1.47 & 2.13 & 1.81\\
			200 & 2.04 & 1.41 &  2.3235  & 3.20\\ 
			500 & 1.32 & 1.00 & 1.73 & 1.78\\
			1000 & 0.83 & 0.74 & 1.33 & 1.71 \\  \bottomrule
		\end{tabular}
		\caption{Variance and mean squared error (MSE) of the maximum likelihood for $\sigma$ obtained using 50, 100, 200, 500 and 1000 particles. Values for variances and MSE are given in unit of $10^{-3}$}
		\label{table:mleSigma}
	\end{table}

	\begin{figure}[htb]
		\centering
		\begin{minipage}{0.4\textwidth}
			\centering
			\includegraphics[width=0.97\linewidth]{/home/raphael/dissertation/figures/mleRicker_r_prior_500.pdf}
		\end{minipage}
		\begin{minipage}{0.4\textwidth}
			\centering
			\includegraphics[width=0.97\linewidth]{/home/raphael/dissertation/figures/mleRicker_r_gamma_500.pdf}
		\end{minipage}
		\caption{}
		\label{fig:comparisonR}
	\end{figure}
	
	\begin{figure}[htb]
		\centering
		\begin{minipage}{0.4\textwidth}
			\centering
			\includegraphics[width=0.97\linewidth]{/home/raphael/dissertation/figures/traceRickerSameV1.pdf}
		\end{minipage}
		\begin{minipage}{0.4\textwidth}
			\centering
			\includegraphics[width=0.97\linewidth]{/home/raphael/dissertation/figures/traceRickerSameV2.pdf}
		\end{minipage}
		\begin{minipage}{0.4\textwidth}
			\centering
			\includegraphics[width=0.97\linewidth]{/home/raphael/dissertation/figures/traceRickerSameV3.pdf}
		\end{minipage}
		\caption{Traceplot of the samples from the posterior density of \textbf{(top left)} $r$, \textbf{(top right)} $\phi$ and \textbf{(bottom)} $\sigma$.}
		\label{fig:traceplotDiag}
	\end{figure}
	
	\begin{figure}[htb]
		\centering
		\begin{minipage}{0.4\textwidth}
			\centering
			\includegraphics[width=0.97\linewidth]{/home/raphael/dissertation/figures/acfRickerSameV1.pdf}
		\end{minipage}
		\begin{minipage}{0.4\textwidth}
			\centering
			\includegraphics[width=0.97\linewidth]{/home/raphael/dissertation/figures/acfRickerSameV2.pdf}
		\end{minipage}
		\begin{minipage}{0.4\textwidth}
			\centering
			\includegraphics[width=0.97\linewidth]{/home/raphael/dissertation/figures/acfRickerSameV3.pdf}
		\end{minipage}
		\caption{Autocorrelation function of the samples from the posterior density of \textbf{(top left)} $r$, \textbf{(top right)} $\phi$ and \textbf{(bottom)} $\sigma$. The \textbf{(red)} is the theoretical asymptotic 95\% significance threshold.}
		\label{fig:acfDiag}
	\end{figure}
	
	\begin{figure}[htb]
		\centering
		\begin{minipage}{0.4\textwidth}
			\centering
			\includegraphics[width=0.97\linewidth]{/home/raphael/dissertation/figures/runningRickerSame1.pdf}
		\end{minipage}
		\begin{minipage}{0.4\textwidth}
			\centering
			\includegraphics[width=0.97\linewidth]{/home/raphael/dissertation/figures/runningRickerSame2.pdf}
		\end{minipage}
		\begin{minipage}{0.4\textwidth}
			\centering
			\includegraphics[width=0.97\linewidth]{/home/raphael/dissertation/figures/runningRickerSame3.pdf}
		\end{minipage}
		\caption{Running means of the samples from the posterior density of \textbf{(top left)} $r$, \textbf{(top right)} $\phi$ and \textbf{(bottom)} $\sigma$.}
		\label{fig:rmDiag}
	\end{figure}
	
	\begin{table}[htb]
		\centering
		\ra{1.3}
		\begin{tabular}{@{}cccc@{}} \toprule
			Parameter & Wood's MSE & LibBi MSE & our MSE\\ \midrule 
			$r$ & 0.0152 & 0.0080 &  0.0086 \\ 
			$\phi$ & 0.012 & 0.096 &  0.079 \\ 
			$\sigma$ & 0.0526 & 0.002 & 0.0023  \\ \bottomrule
		\end{tabular}
		\caption{Median squared errors of the posterior means obtained by Wood and in our study.}
		\label{table:mse}
	\end{table}

\clearpage
	\begin{table}[htb]
		\centering
		\ra{1.3}
		\begin{tabular}{@{}ccccc@{}} \toprule
			Method & Median &  Inter-quartile range & 1\textsuperscript{st} quartile & 3\textsuperscript{rd} quartile \\ \midrule 
			Wood & 0.003 & 0.015 & 0.001 & 0.016\\ 
			LibBi & 0.0089 & 0.011 & 0.00358 & 0.0144 \\ 
			Our implementation & 0.0083 &  0.016 & 0.0043 & 0.020\\ \bottomrule
		\end{tabular}
		\caption{Values obtained for Wood's custom error measure with the four methods.}
		\label{table:metric}
	\end{table}

\clearpage

	\bibliographystyle{plain}
	\bibliography{mybib}{}
	
	\section{Appendix}
	\subsection{Appendix I} \label{KLRicker}
	In this section we present the minimization of the KL divergence between a Lognormal a Gamma distributions.
	We have
	\begin{equation*}
	D_{KL}(P||Q)(\alpha, \theta) = \int_{0}^{\infty}{p(z|\mu, \sigma^2)\log(\frac{p(z|\mu, \sigma^2)}{q(z|\alpha, \theta)})\mathrm{d}z}
	\end{equation*}
	where $p$ is the probability density function of a $\log\mathcal{N}(\mu, \sigma^2)$ and $q$ of a Gamma with shape $\alpha$ and scale $\theta$. \\
	Expanding we obtain:
	\begin{equation*}
	D_{KL}(P||Q)(\alpha, \theta) = C + \alpha\log\theta + \log\Gamma(\alpha) - (\alpha-1)\mathbb{E}_p[\log(Z)] + \frac{1}{\theta}\mathbb{E}_p[Z]
	\end{equation*}
	where $\mathbb{E}_p$ is the expectation with respect to the probability measure $p$.\\
	Therefore:
	\begin{equation*}
	\frac{\partial }{\partial \alpha}(D_{KL}(P||Q)) = \log(\theta) + \psi^{(0)}(\alpha)-\mathbb{E}_p[\log(Z)]
	\end{equation*}
	\begin{equation*}
	\frac{\partial }{\partial \theta}(D_{KL}(P||Q)) = \frac{\alpha}{\theta} - \frac{1}{\theta^2}\mathbb{E}_p[Z]
	\end{equation*}
	where $\psi^{(0)}$ is the digamma function.
	
	Since $\mathbb{E}_p[\log(Z)]=\mu$ and $\mathbb{E}_p[Z] = e^{\mu+\frac{\sigma^2}{2}}$, we finally have that, setting the partial derivatives to zero, the solutions satisfy:
	\[	\begin{cases}
	 & \alpha=e^{\psi^{(0)}(\alpha)+\frac{\sigma^2}{2}} \\
	& \theta=\frac{1}{\alpha}e^{\mu+\frac{\sigma^2}{2}}
	\end{cases}\]

	If we use the first terms of the asymptotic expansion of the digamma function, i.e $\psi^{(0)}(\alpha) \approx \log(\alpha)-\frac{1}{2\alpha}$, we finally have $\alpha =\frac{1}{\sigma^2}$ and $\theta=\frac{1}{\alpha}e^{\mu+\frac{\sigma^2}{2}}$. \\
	
	In order to check if the solutions are indeed minima, we calculated the Hessian of $D_{KL}(P||Q)(\alpha, \theta)$ i.e
	\begin{equation*}
		\text{H} = \begin{pmatrix}
		\frac{\strut \partial^2 D_{KL}(P||Q)}{\strut \partial \alpha^2} & \frac{\strut \partial^2 D_{KL}(P||Q) }{\strut \partial \theta \partial \alpha} \\
		\frac{\strut \partial^2 D_{KL}(P||Q)}{\strut \partial \theta \partial \alpha} & \frac{\strut \partial^2 D_{KL}(P||Q)}{\strut \partial \theta^2} 
		\end{pmatrix} =
		\begin{pmatrix}
		\psi^{(1)}(\alpha) & \frac{1}{\theta} \\
		\frac{1}{\theta} & -\frac{\alpha}{\theta^2}+\frac{2e^{\mu +\frac{\sigma^2}{2}}}{\theta^3}
		\end{pmatrix}
	\end{equation*}
	Straightforward calculations yield that the sign of the determinant of the above Hessian is such that $\text{sign}(\det{H}) = \psi^{(1)}(\alpha)(\frac{2}{\theta^3}e^{\mu +\frac{\sigma^2}{2}} - \alpha) - 1$.
\end{document}